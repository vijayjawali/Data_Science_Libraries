{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRAPY BASICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy is a fast, open-source web crawling framework written in Python, used to extract the data from the web page with the help of selectors based on XPath."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>create a new project in PyCharm</li>\n",
    "<li>Go to File -> Settings -> python Interpreter</li>\n",
    "<li>Add Scrapy to the list of interpreters</li>\n",
    "<li>Go to Terminal and type: scrapy startproject \"myproject\" </li>\n",
    "<li>A subdirectory named myproject will be created in the current directory</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"scrapy_project_creation.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"new_project_structure.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating first spider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Go to spiders folder</li>\n",
    "<li>create a python file quotes_tutorial.py</li>\n",
    "<li>Go to terminal and navigate to folder cd .\\quotetutorial\\</li>\n",
    "<li>Go to terminal and type: scrapy crawl quotes</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open scrapy in shell mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Go to terminal and type: scrapy shell \"https://quotes.toscrape.com/\"</li>\n",
    "\n",
    "In [1]: response.css(\"title\")\n",
    "\n",
    "Out[1]: [\\<Selector xpath='descendant-or-self::title' data='\\<title>Quotes to Scrape</title>\\n    \\<...'\\>]\n",
    "\n",
    "\n",
    "In [3]: response.css('title::text').extract()\n",
    "\n",
    "Out[3]: ['Quotes to Scrape']\n",
    "\n",
    "\n",
    "In [4]: response.css('title::text').extract_first()\n",
    "\n",
    "Out[4]: 'Quotes to Scrape'\n",
    "\n",
    "\n",
    "<li>extract() returns error when Title is unavailable, but extract_first() returns None instead of error</li>\n",
    "\n",
    "In [5]: response.css(\"span.text::text\").extract()\n",
    "Out[5]: \n",
    "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',\n",
    "\n",
    " '“It is our choices, Harry, that show what we truly are, far more than our abilities.”',\n",
    "\n",
    " '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',\n",
    "\n",
    " '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”',\n",
    "\n",
    " \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\",\n",
    "\n",
    " '“Try not to become a man of success. Rather become a man of value.”',\n",
    "\n",
    " '“It is better to be hated for what you are than to be loved for what you are not.”',\n",
    "\n",
    " \"“I have not failed. I've just found 10,000 ways that won't work.”\",\n",
    "\n",
    " \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\",\n",
    " \n",
    " '“A day without sunshine is like, you know, night.”']\n",
    "\n",
    "In [6]: response.css(\"span.text::text\")[1].extract()\n",
    "\n",
    "Out[6]: '“It is our choices, Harry, that show what we truly are, far more than our abilities.”'\n",
    "\n",
    "In [7]: response.css(\".author::text\").extract()\n",
    "\n",
    "Out[7]: \n",
    "['Albert Einstein',\n",
    " 'J.K. Rowling',\n",
    " 'Albert Einstein',\n",
    " 'Jane Austen',\n",
    " 'Marilyn Monroe',\n",
    " 'Albert Einstein',\n",
    " 'André Gide',\n",
    " 'Thomas A. Edison',\n",
    " 'Eleanor Roosevelt',\n",
    " 'Steve Martin']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### installing SelectorGadget chrome extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Google search \"Selector Gadget Chrome\"</li>\n",
    "<li>Go to chrome://extensions</li>\n",
    "<li>Click on the extension icon and add extension</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using SelectorGadget\n",
    "\n",
    "<li>Select on the things you need to scrape on page</li>\n",
    "<li>Copy the text from extension .a-color-base.a-text-normal</li>\n",
    "<li>Go to terminal</li>\n",
    "\n",
    "scrapy shell \"https://www.amazon.in/s?k=s22+samsung&crid=163A3PO1H6GYM&sprefix=s2\n",
    "2+samsung%2Caps%2C383&ref=nb_sb_noss\"\n",
    "\n",
    "\n",
    "In [1]: response.css(\".a-color-base.a-text-normal::text\")[1].extract()\n",
    "\n",
    "Out[1]: 'Samsung Galaxy S21 FE 5G (Graphite, 8GB, 256GB Storage)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data with xpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrapy shell \"https://quotes.toscrape.com/\"\n",
    "\n",
    "In [2]: response.xpath(\"//title/text()\").extract()\n",
    "\n",
    "Out[2]: ['Quotes to Scrape']\n",
    "\n",
    "In [3]: response.xpath(\"//span[@class='text']/text()\").extract()\n",
    "\n",
    "Out[3]: ['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',\n",
    " '“It is our choices, Harry, that show what we truly are, far more than our abilities.”',\n",
    " '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',\n",
    " '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”',\n",
    " \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\",\n",
    " '“Try not to become a man of success. Rather become a man of value.”',\n",
    " '“It is better to be hated for what you are than to be loved for what you are not.”',\n",
    " \"“I have not failed. I've just found 10,000 ways that won't work.”\",\n",
    " \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\",\n",
    " '“A day without sunshine is like, you know, night.”']\n",
    "\n",
    "In [4]: response.xpath(\"//span[@class='text']/text()\")[1].extract()\n",
    "\n",
    "Out[4]: '“It is our choices, Harry, that show what we truly are, far more than our abilities.”'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data with css along with xpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [5]: response.css(\"li.next a\").xpath(\"@href\").extract()\n",
    "\n",
    "Out[5]: ['/page/2/']\n",
    "\n",
    "In [6]: response.css(\"a\").xpath(\"@href\").extract()\n",
    "\n",
    "Out[6]: \n",
    "['/',\n",
    " '/login',\n",
    " '/author/Albert-Einstein',\n",
    " '/tag/change/page/1/',\n",
    " '/tag/deep-thoughts/page/1/',\n",
    " '/tag/thinking/page/1/',\n",
    " '/tag/world/page/1/',\n",
    " '/author/J-K-Rowling',\n",
    " '/tag/abilities/page/1/',\n",
    " '/tag/choices/page/1/',\n",
    " '/author/Albert-Einstein',\n",
    " '/tag/inspirational/page/1/',\n",
    " '/tag/life/page/1/',\n",
    " '/tag/live/page/1/',\n",
    " '/tag/miracle/page/1/',\n",
    " '/tag/miracles/page/1/',\n",
    " '/author/Jane-Austen',\n",
    " '/tag/aliteracy/page/1/',\n",
    " '/tag/books/page/1/',\n",
    " '/tag/classic/page/1/',\n",
    " '/tag/humor/page/1/',\n",
    " '/author/Marilyn-Monroe',\n",
    " '/tag/be-yourself/page/1/',\n",
    " '/tag/inspirational/page/1/',\n",
    " '/author/Albert-Einstein',\n",
    " '/tag/adulthood/page/1/',\n",
    " '/tag/success/page/1/',\n",
    " '/tag/value/page/1/',\n",
    " '/author/Andre-Gide',\n",
    " '/tag/life/page/1/',\n",
    " '/tag/love/page/1/',\n",
    " '/author/Thomas-A-Edison',\n",
    " '/tag/edison/page/1/',\n",
    " '/tag/failure/page/1/',\n",
    " '/tag/inspirational/page/1/',\n",
    " '/tag/paraphrased/page/1/',\n",
    " '/author/Eleanor-Roosevelt',\n",
    " '/tag/misattributed-eleanor-roosevelt/page/1/',\n",
    " '/author/Steve-Martin',\n",
    " '/tag/humor/page/1/',\n",
    " '/tag/obvious/page/1/',\n",
    " '/tag/simile/page/1/',\n",
    " '/page/2/',\n",
    " '/tag/love/',\n",
    " '/tag/inspirational/',\n",
    " '/tag/life/',\n",
    " '/tag/humor/',\n",
    " '/tag/books/',\n",
    " '/tag/reading/',\n",
    " '/tag/friendship/',\n",
    " '/tag/friends/',\n",
    " '/tag/truth/',\n",
    " '/tag/simile/',\n",
    " 'https://www.goodreads.com/quotes',\n",
    " 'https://scrapinghub.com']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating items to temporarily store scrapped data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li> Go to items.py file</li>\n",
    "<li> define the fields</li>\n",
    "<li> Import the python file in spider/quotes_spider.py</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing scrapped data in JSON, XML or CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Go to terminal and navigate to folder cd .\\quotetutorial\\</li>\n",
    "\n",
    "##### JSON\n",
    "<li>Go to terminal and type: scrapy crawl quotes -o items.json</li>\n",
    "\n",
    "\n",
    "##### XML\n",
    "<li>Go to terminal and type: scrapy crawl quotes -o items.xml</li>\n",
    "\n",
    "##### CSV\n",
    "<li>Go to terminal and type: scrapy crawl quotes -o items.csv</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li> Go to settings.py file</li>\n",
    "<li> Uncomment ITEM_PIPELINES</li>\n",
    "<li> set the priority of the pipeline if there are multiple pipelines</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing in SQLite database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li> Go to pipeline.py file</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "\n",
    "\n",
    "# class QuotetutorialPipeline(object):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self.create_connection()\n",
    "#         self.create_table()\n",
    "\n",
    "#     def create_connection(self):\n",
    "#         self.conn = sqlite3.connect(\"myquotes.db\")\n",
    "#         self.curr = self.conn.cursor()\n",
    "\n",
    "#     def create_table(self):\n",
    "#         self.curr.execute(\"\"\"CREATE TABLE IF NOT EXISTS quotes_tb(\n",
    "#             title TEXT,\n",
    "#             author TEXT,\n",
    "#             tag TEXT\n",
    "#         )\"\"\")\n",
    "\n",
    "#     def process_item(self, item, spider):\n",
    "#         self.store_db(item)\n",
    "#         print(\"Pipeline :\" + item['title'][0])\n",
    "#         return item\n",
    "\n",
    "#     def store_db(self, item):\n",
    "#         self.curr.execute(\"\"\"INSERT INTO quotes_tb VALUES (?,?,?)\"\"\",(\n",
    "#             item['title'][0],\n",
    "#             item['author'][0],\n",
    "#             item['tag'][0]\n",
    "#         ))\n",
    "#         self.conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li> Go to https://sqliteonline.com/ </li>\n",
    "<li> Go to File and browse to the folder wher the database file is available</li>\n",
    "<li> Go to terminal and type: scrapy crawl quotes</li>\n",
    "\n",
    "<img src=\"sqlite_database.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # next_page = response.css('li.next a::attr(href)').get()\n",
    "        # print(next_page)\n",
    "\n",
    "        # if next_page is not None:\n",
    "        #     yield response.follow(next_page, callback=self.parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping using pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # next_page = 'http://quotes.toscrape.com/page/' + str(QuoteSpider.page_number) + '/'\n",
    "\n",
    "        # if QuoteSpider.page_number < 11:\n",
    "        #     QuoteSpider.page_number += 1\n",
    "        #     yield response.follow(next_page, callback=self.parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Logging in with Scrapy FormRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li> Click onm login button</li>\n",
    "<li> Enter username and password</li>\n",
    "<li> Go to inspect element</li>\n",
    "<li> Go to network tab</li>\n",
    "<li> Click on the login</li>\n",
    "<li> Go to Payload tab</li>\n",
    "<li> csrf_token can be seen in the payload</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class QuoteSpider(scrapy.Spider):\n",
    "#     name = \"quotes\"\n",
    "#     start_urls = [\n",
    "#         'http://quotes.toscrape.com/login'\n",
    "#     ]\n",
    "\n",
    "#     def parse(self, response):\n",
    "#         token = response.css('form input::attr(value)').extract_first()\n",
    "#         print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AYowUResZEPBCxytWdqKFguQkvMzNnbXJiGacpTSDmhILOjfVHrl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating spiders automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li> Go to Terminal and typoe Command : scrapy startproject amazontutorial</li>\n",
    "\n",
    "##### OUTPUT \n",
    "\n",
    "New Scrapy project 'amazontutorial', using template directory \n",
    "\n",
    "'C:\\Users\\vijay\\anaconda3\\envs\\data_science\\lib\\site-packages\\scrapy\\templates\\project',\n",
    " created in:\n",
    " \n",
    "    C:\\Users\\vijay\\Jupyter Lab Scripts\\Data_Science_Libraries\\SCRAPY\\amazontutorial\n",
    "\n",
    "You can start your first spider with:\n",
    "\n",
    "    cd amazontutorial\n",
    "    \n",
    "    scrapy genspider example example.com\n",
    "\n",
    "PS C:\\Users\\vijay\\Jupyter Lab Scripts\\Data_Science_Libraries\\SCRAPY> cd .\\amazontutorial\\\n",
    "\n",
    "PS C:\\Users\\vijay\\Jupyter Lab Scripts\\Data_Science_Libraries\\SCRAPY\\amazontutorial> scrapy genspider \n",
    "\n",
    "amazon_spider amazon.com\n",
    "\n",
    "Created spider 'amazon_spider' using template 'basic' in module:\n",
    "    \n",
    "    amazontutorial.spiders.amazon_spider\n",
    "\n",
    "<img src=\"amazon_spider_creation.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting User Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li> Go to settings.py file</li>\n",
    "<li> Uncomment USER_AGENT</li>\n",
    "<li> Google search \"googlebot user agent\"</li>\n",
    "<li> COPY : Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html) </li>\n",
    "<li> Paste in variable USER_AGENT</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bypass Restrictions using User-Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install scrapy-user-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COPY and Paste in settings.py\n",
    "\n",
    "DOWNLOADER_MIDDLEWARES = {\n",
    "    \n",
    "    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,\n",
    "    'scrapy_user_agents.middlewares.RandomUserAgentMiddleware': 400,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT USER_AGENT in settings.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bypass Restrictions using Proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install scrapy_proxy_pool\n",
    "\n",
    "Repo : https://github.com/rejoiceinhope/scrapy-proxy-pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable this middleware by adding the following settings to your settings.py:\n",
    "\n",
    "PROXY_POOL_ENABLED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COPY and Paste in settings.py\n",
    "DOWNLOADER_MIDDLEWARES = {\n",
    "    \n",
    "    # ...\n",
    "    'scrapy_proxy_pool.middlewares.ProxyPoolMiddleware': 610,\n",
    "    'scrapy_proxy_pool.middlewares.BanDetectionMiddleware': 620,\n",
    "    # ...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
